{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6kC8wgTBfMjK1azWj3c5M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olorunfemibabalola/Bias-Detection-NLP/blob/main/Policy_Bias_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Import modules\n",
        "Import the dataset\n",
        "Perform exploratory data analysis\n",
        "Clean the data\n",
        "Split into training and testing sets\n",
        "Create a model\n",
        "Train the model\n",
        "Make predictions\n",
        "Test the model\n",
        "Evaluate the model\n",
        "Make predictions on new data\n",
        "Persist the model for future use\n",
        "Load a persisted model\n",
        "Make predictions on new data\n",
        "'''"
      ],
      "metadata": {
        "id": "TdVTNgfPevCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "\n"
      ],
      "metadata": {
        "id": "QuT3Jr3ugEAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import fileinput\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "hA28fP8KgFS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "userChoice = input(\"Woud you like to input a text or a file? (text/file)\").lower().strip()\n",
        "while (userChoice != \"text\") and (userChoice != \"file\"):\n",
        "    print(\"Invalid input. Please enter 'text' or 'file'\")\n",
        "    userChoice = input(\"Woud you like to input a text or a file? (text/file)\").lower().strip()\n",
        "else:\n",
        "    print(f\"You have selected {userChoice}\")\n",
        "\n",
        "if userChoice == \"text\":\n",
        "  userText = input(\"Enter your text:\")\n",
        "else:\n",
        "  print(\"Upload your file below:\")\n",
        "  #This creates the \"Upload\" button\n",
        "  uploadedFile = files.upload()\n",
        "\n",
        "  # The 'uploaded' variable is a dictionary:\n",
        "  # Key = filename, Value = file data (bytes)\n",
        "  for filename in uploadedFile.keys():\n",
        "    print(f'User uploaded file \"{filename}\" with a length of {len(uploadedFile[filename])} bytes')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3xd4lIL8Xgtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "215b614e"
      },
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# Define the PDF file name\n",
        "# The filename variable already holds the correct name from previous steps\n",
        "\n",
        "# Open the PDF file in binary read mode\n",
        "reader = PdfReader(filename)\n",
        "\n",
        "# Initialize an empty string to store the extracted text\n",
        "user_file= \"\"\n",
        "\n",
        "# Iterate through each page and extract text\n",
        "for page in reader.pages:\n",
        "    user_file += page.extract_text()\n",
        "\n",
        "# Display a portion of the extracted text to verify\n",
        "print(user_file[:1000])\n",
        "print(f\"Total characters extracted: {len(user_file)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "227c1018"
      },
      "source": [
        "print(user_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_file.lower()\n",
        "new = user_file.split(\".\")"
      ],
      "metadata": {
        "id": "OAe9PvUCVvR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q transformers torch\n",
        "\n",
        "import torch\n",
        "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Step 1: Initialize the Auditor (RoBERTa Encoder)\n",
        "# Specialized for detecting social and cognitive biases\n",
        "auditor = pipeline(\"text-classification\",\n",
        "                   model=\"valurank/distilroberta-bias\",\n",
        "                   device=0 if torch.cuda.is_available() else -1)\n",
        "\n",
        "# Step 2: Initialize the Conversationalist (GPT-2 Decoder)\n",
        "chat_model_name = \"openai-community/gpt2\"\n",
        "chat_tokenizer = AutoTokenizer.from_pretrained(chat_model_name)\n",
        "chat_model = AutoModelForCausalLM.from_pretrained(chat_model_name)\n",
        "\n",
        "def get_chatbot_response(prompt):\n",
        "    # Perform Bias Audit FIRST\n",
        "    audit_result = auditor(prompt)[0]\n",
        "\n",
        "    # If Bias is detected above a 70% confidence threshold\n",
        "    if audit_result['label'] == 'Biased' and audit_result['score'] > 0.7:\n",
        "        return f\"‚ö†Ô∏è [BIAS ALERT]: I detected potential {audit_result['label']} in your prompt. \" \\\n",
        "               f\"Please rephrase to be more inclusive.\"\n",
        "\n",
        "    # Otherwise, generate a standard response\n",
        "    inputs = chat_tokenizer.encode(prompt + chat_tokenizer.eos_token, return_tensors='pt')\n",
        "    outputs = chat_model.generate(inputs, max_length=100, do_sample=True, top_k=50, top_p=0.95)\n",
        "    return chat_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Step 3: Interactive Chat Loop\n",
        "print(\"üõ°Ô∏è Inclusive Assistant Active. Type 'quit' to stop.\")\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in ['quit', 'exit']: break\n",
        "\n",
        "    response = get_chatbot_response(user_input)\n",
        "    print(f\"Bot: {response}\\n\")\n"
      ],
      "metadata": {
        "id": "3uhTroqYdedj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure you have the necessary libraries installed\n",
        "# !pip install -q PyPDF2 gradio transformers torch\n",
        "\n",
        "import PyPDF2\n",
        "import gradio as gr\n",
        "\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    \"\"\"Extracts text from an uploaded PDF file object.\"\"\"\n",
        "    reader = PyPDF2.PdfReader(pdf_file.name)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        content = page.extract_text()\n",
        "        if content:\n",
        "            text += content + \" \"\n",
        "    return text\n",
        "\n",
        "def audit_document(file):\n",
        "    \"\"\"Scans the entire document and returns biased sentences.\"\"\"\n",
        "    if file is None:\n",
        "        return \"No file uploaded.\"\n",
        "\n",
        "    text = extract_text_from_pdf(file)\n",
        "    sentences = text.split('.')\n",
        "    biased_findings = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        clean_sentence = sentence.strip()\n",
        "        if len(clean_sentence) > 10: # Filter out noise\n",
        "            result = auditor(clean_sentence)[0]\n",
        "            if result['label'] == 'Biased' and result['score'] > 0.75:\n",
        "                biased_findings.append(f\"‚Ä¢ \\\"{clean_sentence}\\\" (Confidence: {result['score']:.2f})\")\n",
        "\n",
        "    if not biased_findings:\n",
        "        return \"‚úÖ No biased statements found. The document is safe and inclusive.\"\n",
        "    else:\n",
        "        report = \"‚ö†Ô∏è Potential bias detected in the following statements:\\n\\n\" + \"\\n\".join(biased_findings)\n",
        "        return report\n",
        "\n",
        "# Updated Chatbot Logic with \"Document Upload\" Intent\n",
        "def chatbot_response(message, history):\n",
        "    message_lower = message.lower()\n",
        "\n",
        "    # Feature 1: Check for Document Intent\n",
        "    if any(word in message_lower for word in [\"upload\", \"document\", \"file\", \"scan\"]):\n",
        "        return \"Sure! Please use the **Upload File** button below to provide your document for a bias audit.\"\n",
        "\n",
        "    # Feature 2: Standard Chat Audit\n",
        "    res = auditor(message)[0]\n",
        "    if res['label'] == 'Biased':\n",
        "        return f\"‚ö†Ô∏è BIAS ALERT: I detected potential {res['label']} in your input. Try using neutral phrasing.\"\n",
        "\n",
        "    return \"‚úÖ Inclusive input. I am ready to help with your policy questions.\"\n",
        "\n",
        "# UI Layout (Using Gradio Blocks for better control)\n",
        "with gr.Blocks(theme=\"soft\") as demo:\n",
        "    gr.Markdown(\"# üõ°Ô∏è Inclusive Policy Assistant & Auditor\")\n",
        "\n",
        "    with gr.Tab(\"Chat\"):\n",
        "        gr.ChatInterface(chatbot_response)\n",
        "\n",
        "    with gr.Tab(\"Document Audit\"):\n",
        "        file_input = gr.File(label=\"Upload Corporate Policy (PDF)\")\n",
        "        audit_output = gr.Textbox(label=\"Audit Report\", lines=10)\n",
        "        audit_button = gr.Button(\"Run Audit\")\n",
        "        audit_button.click(audit_document, inputs=file_input, outputs=audit_output)\n",
        "\n",
        "demo.launch(debug=True)\n"
      ],
      "metadata": {
        "id": "K2qYD1YWaCi9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}